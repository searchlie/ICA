{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d56823",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def changeshapeDF_Fastingmice(DF):\n",
    "        def mkZscore(DF,IndLabel,ColLabel,axis):\n",
    "            if axis=='col':##zscore in column direction\n",
    "                ax=0\n",
    "            else:##zscore in row direction\n",
    "                ax=1\n",
    "            meanNP = np.array(DF) -np.nanmean(np.array(DF),axis=ax,keepdims=True)\n",
    "            stdNP = np.nanstd(np.array(DF),axis=ax)\n",
    "            signDF = pd.DataFrame(index=IndLabel,columns=ColLabel)\n",
    "            if axis=='col':\n",
    "                for i in range(len(ColLabel)): \n",
    "                    ZscoredNP = meanNP[:,i]/stdNP[i]\n",
    "                    ZscoredDF[ColLabel[i]] = ZscoredNP  \n",
    "            else:    \n",
    "                for i in range(len(IndLabel)): \n",
    "                    ZscoredNP = meanNP[i,:]/stdNP[i]\n",
    "                    ZscoredDF.loc[IndLabel[i]] = ZscoredNP\n",
    "            return(ZscoredDF) \n",
    "        timepoint=[0,2,4,6,8,12,16,24]\n",
    "        condition=['WT','OB']\n",
    "        #DF = DF[DF.max(axis=1)>5] ##old Threshold\n",
    "        NewDF = pd.DataFrame(np.array(mkZscore(np.log(DF1+1),list(DF.index),list(DF.columns),'row').fillna(0)) )  \n",
    "        NewDF.index=list(DF.index); NewDF.columns=list(DF.columns)\n",
    "        \n",
    "        Dict=dict() ##Organize by label\n",
    "        for i in range(len(timepoint)*len(condition)):\n",
    "            Dict[i] = DF.iloc[:,0+(5*i):5+(5*i)]\n",
    "            if i==0:\n",
    "                WT_MeanStack = pd.DataFrame(Dict[0].mean(axis=1))\n",
    "                WT_SemStack = pd.DataFrame(Dict[0].sem(axis=1))\n",
    "            elif i<=len(timepoint):\n",
    "                WT_MeanStack = pd.concat( [WT_MeanStack,pd.DataFrame(Dict[i+1].mean(axis=1))],axis=1)\n",
    "                WT_SemStack = pd.concat( [WT_SemStack,pd.DataFrame(Dict[i+1].sem(axis=1))],axis=1)\n",
    "            elif i == len(timepoint)+1:\n",
    "                OB_MeanStack = pd.DataFrame(Dict[0].mean(axis=1))\n",
    "                OB_SemStack = pd.DataFrame(Dict[0].sem(axis=1))\n",
    "            else:\n",
    "                OB_MeanStack = pd.concat( [OB_MeanStack,pd.DataFrame(Dict[i+1].mean(axis=1))],axis=1)\n",
    "                OB_SemStack = pd.concat( [OB_SemStack,pd.DataFrame(Dict[i+1].sem(axis=1))],axis=1)\n",
    "                              \n",
    "        WTOBHstack_mean = np.hstack([WT_MeanStack,OB_MeanStack])  \n",
    "        WTOBHstack_sem = np.hstack([WTStack,OBStack])  \n",
    "\n",
    "        \n",
    "        return(NewDF,DF,WTOBHstack_mean,WTOBHstack_sem)\n",
    "    \n",
    "    def ScreenData_Fastingmice(DF):\n",
    "        ObDF = pd.read_excel('../timecourse_fasting/result-edgeR/result-obob_onewayAnovaLike.xlsx',header=0,index_col=0)     \n",
    "        WtDF = pd.read_excel('../timecourse_fasting/result-edgeR/result-WT_onewayAnovaLike.xlsx',header=0,index_col=0)     \n",
    "        qval = 0.1\n",
    "        ObList=list(ObDF[ObDF['FDR']<qval].index)\n",
    "        WtList=list(WtDF[WtDF['FDR']<qval].index)\n",
    "        \n",
    "        CombList=list(set(ObList)|set(WtList))\n",
    "        \n",
    "        return(DF.loc[CombList])\n",
    "    \n",
    "    def ScreenData_Fastingmice_EdgeR(DF):\n",
    "        Ob02DF = pd.read_excel('../timecourse_fasting/result-edgeR/obob_0h_vs_obob_2h_DEG.xlsx',header=0,index_col=0)     \n",
    "        Ob04DF = pd.read_excel('../timecourse_fasting/result-edgeR/obob_0h_vs_obob_4h_DEG.xlsx',header=0,index_col=0)     \n",
    "        Ob06DF = pd.read_excel('../timecourse_fasting/result-edgeR/obob_0h_vs_obob_6h_DEG.xlsx',header=0,index_col=0)     \n",
    "        Ob08DF = pd.read_excel('../timecourse_fasting/result-edgeR/obob_0h_vs_obob_8h_DEG.xlsx',header=0,index_col=0)     \n",
    "        Ob012DF = pd.read_excel('../timecourse_fasting/result-edgeR/obob_0h_vs_obob_12h_DEG.xlsx',header=0,index_col=0)     \n",
    "        Ob016DF = pd.read_excel('../timecourse_fasting/result-edgeR/obob_0h_vs_obob_16h_DEG.xlsx',header=0,index_col=0)     \n",
    "        Ob024DF = pd.read_excel('../timecourse_fasting/result-edgeR/obob_0h_vs_obob_24h_DEG.xlsx',header=0,index_col=0)     \n",
    "        \n",
    "        Wt02DF = pd.read_excel('../timecourse_fasting/result-edgeR/WT_0h_vs_WT_2h_DEG.xlsx',header=0,index_col=0)     \n",
    "        Wt04DF = pd.read_excel('../timecourse_fasting/result-edgeR/WT_0h_vs_WT_4h_DEG.xlsx',header=0,index_col=0)     \n",
    "        Wt06DF = pd.read_excel('../timecourse_fasting/result-edgeR/WT_0h_vs_WT_6h_DEG.xlsx',header=0,index_col=0)     \n",
    "        Wt08DF = pd.read_excel('../timecourse_fasting/result-edgeR/WT_0h_vs_WT_8h_DEG.xlsx',header=0,index_col=0)     \n",
    "        Wt012DF = pd.read_excel('../timecourse_fasting/result-edgeR/WT_0h_vs_WT_12h_DEG.xlsx',header=0,index_col=0)     \n",
    "        Wt016DF = pd.read_excel('../timecourse_fasting/result-edgeR/WT_0h_vs_WT_16h_DEG.xlsx',header=0,index_col=0)     \n",
    "        Wt024DF = pd.read_excel('../timecourse_fasting/result-edgeR/WT_0h_vs_WT_24h_DEG.xlsx',header=0,index_col=0)     \n",
    "        qval = 0.1\n",
    "        ObList=list(Ob02DF[Ob02DF['FDR']<0.1].index)+list(Ob04DF[Ob04DF['FDR']<0.1].index)+list(Ob06DF[Ob06DF['FDR']<0.1].index)+list(Ob08DF[Ob08DF['FDR']<0.1].index)+list(Ob012DF[Ob012DF['FDR']<0.1].index)+list(Ob016DF[Ob016DF['FDR']<0.1].index)+list(Ob024DF[Ob024DF['FDR']<0.1].index)\n",
    "        WtList=list(Wt02DF[Wt02DF['FDR']<0.1].index)+list(Wt04DF[Wt04DF['FDR']<0.1].index)+list(Wt06DF[Wt06DF['FDR']<0.1].index)+list(Wt08DF[Wt08DF['FDR']<0.1].index)+list(Wt012DF[Wt012DF['FDR']<0.1].index)+list(Wt016DF[Wt016DF['FDR']<0.1].index)+list(Wt024DF[Wt024DF['FDR']<0.1].index)\n",
    "        \n",
    "        CombList=list(set(ObList)|set(WtList))\n",
    "        \n",
    "        return(DF.loc[CombList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826dae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    LiverDF = pd.read_excel('../timecourse_fasting/fasting-transcriptome-FPKM.xlsx',header=0,index_col=0)\n",
    "    NameDF  = pd.read_csv('../timecourse_fasting/sample_info_liver.csv',header=0,index_col=0)\n",
    "    \n",
    "    \n",
    "    LiverDF = LiverDF.drop('organ',axis=0)\n",
    "    ForLabel = LiverDF.iloc[[0,1],1:]\n",
    "    LiverDF = LiverDF.drop(['genotype','timepoint'],axis=0)\n",
    "    #LiverDF = ScreenData_Fastingmice(LiverDF)\n",
    "    LiverDF =ScreenData_Fastingmice_EdgeR(LiverDF)\n",
    "\n",
    "    #LiverDF.index = list(LiverDF['Name'])\n",
    "\n",
    "  \n",
    "    TensorClss = HTH.miceFasting_class()\n",
    "    LiverNewDF, BloodDict = TensorClss.DelNaN(LiverDF,'any')\n",
    "    LiverNewDF.columns=[str(i) +'_' +str(j) for i, j in zip(ForLabel.loc['genotype'],ForLabel.loc['timepoint'])]\n",
    "\n",
    "    #print(LiverNewDF)\n",
    "    LiverNewDF=LiverNewDF.astype(float)\n",
    "    NormalizedLiverDF,RawDF,WTOBHstack_mean,WTOBHstack_sem= changeshapeDF_Fastingmice(LiverNewDF)\n",
    "    #NormalizedLiverDF,RawDF= changeshapeDF_Fastingmice_MoritaNmrz(LiverNewDF)\n",
    "    NormalizedLiverDF.to_excel(save_dir+'NormalizedLiver_FastingDF.xlsx')\n",
    "    \n",
    "    WTOBHstack_mean=pd.DataFrame(WTOBHstack_mean);WTOBHstack_mean.index=list(NormalizedLiverDF.index)\n",
    "    \n",
    "    WTOBHstack_std=pd.DataFrame(WTOBHstack_sem);WTOBHstack_std.index=list(NormalizedLiverDF.index)\n",
    "\n",
    "    OptionDict={};OptionDict['std']=WTOBHstack_std\n",
    "    \n",
    "    #TensorClss.Reconstruction_Timecourse_miceFasting(WTOBHstack_mean,OptionDict,save_dir)\n",
    "    \n",
    "    #DuplMolLabel=[BloodDict[Label[i]] for i in range(len(Label))]\n",
    "    \n",
    "    #### 前処理にPCA\n",
    "    \n",
    "    PCAClss = PCA_class()\n",
    "    ICAClss = ICA_class()\n",
    "        \n",
    "    #X = PCAClss.df_z(Data, axis=1) #遺伝子ごとにZスコア化\n",
    "    X=NormalizedLiverDF#.fillna(0)\n",
    "\n",
    "    NumNan = RawDF.isnull().sum(axis=1)\n",
    "    OptionDict['NumNan']=NumNan\n",
    "\n",
    "    # ICAを繰り返す（並列化）\n",
    "    num_of_rep = 100\n",
    "    #pca_score,pca_coef,cov_ratio,pca_components_,W,v = PCAHel.PCA(X,None)#この時点でscore,loading,label,LabelPropの順番は対応している\n",
    "    #X = pd.DataFrame(np.dot(pca_score, pca_components_) )\n",
    "    #X.index=Data.index; X.columns=Data.columns\n",
    "    \n",
    "    #pca = PCA(n_components=38, whiten=False, random_state=1)\n",
    "    #x_train_pca = pca.fit_transform(X)\n",
    "     \n",
    "    # 再構成\n",
    "    #X = pd.DataFrame(pca.inverse_transform(x_train_pca))\n",
    "    #X.index=Data.index; X.columns=Data.columns\n",
    "\n",
    "    #独立成分の数\n",
    "    k =80#100\n",
    "\n",
    "    W,S = ICAClss.robust_ica(X, save_dir,k, num_of_rep)\n",
    "\n",
    "    # metasampleを計算、独立成分を説明率でソートする\n",
    "    S = W.T.dot(X).T\n",
    "    S.columns = [s.replace(\"metagene\",\"metasample\") for s in S.columns]\n",
    "    metagenes, metasamples, ICAexplain = ICAClss.ICAsort(X, W, S)\n",
    "    \n",
    "    metagenes.to_excel(save_dir+'MolScore.xlsx')\n",
    "    metasamples.to_excel(save_dir+'SampleScore.xlsx')    \n",
    "    # 計算したICまでで説明率を表示\n",
    "    print(\"{:.2%}\".format(sum(ICAexplain)) + \" data explained by \" + str(k) + \" metamol\")\n",
    "\n",
    "    qvalcutoff=0.1\n",
    "    #print(ICAClss.metagenes_top(metagenes, qvalcutoff))\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    PCAHel.plotPCACovRatio(ICAexplain)\n",
    "    plt.xticks(size='10',rotation=270);plt.yticks(size='40')\n",
    "    plt.savefig(save_dir + 'PCExplained.pdf',bbox_inches=\"tight\")\n",
    "    plt.savefig(save_dir + 'PCExplained.png',bbox_inches=\"tight\")   \n",
    "\n",
    "    #ICAClss.CategoricalRegression_AdjR(ClusterMeanMetasamples,save_dir)\n",
    "    #ICAClss.CategoricalRegression_Indiv_AdjR(ClusterMeanMetasamples,save_dir)\n",
    "    #ICAClss.CategoricalRegression_Indiv_Time_AdjR(ClusterMeanMetasamples,save_dir)\n",
    "   \n",
    "    ###カテゴリカル回帰で有意な時点を含んだ成分の確認\n",
    "    #ICAClss.Analeachcomponents(ClusterMeanMetasamples,ClusterMeanMetagenes,save_dir)   \n",
    "    #IntVar,BetwVar = ICAClss.InterVarianceBetweenVariance(ClusterMeanMetasamples,save_dir)\n",
    "    #ICAClss.InterVarianceBetweenVariancePlot(IntVar,BetwVar,save_dir) \n",
    "    ICAClss.metagenes_topBH(metagenes, qvalcutoff, BloodDict,WTOBHstack_mean, OptionDict,save_dir)\n",
    "\n",
    "    pvals = ICAClss.ANOVA_Time_Indiv_Fasting(metasamples,ICAexplain,save_dir)\n",
    "\n",
    "    #pvals = pd.read_excel('/Users/fujita/Google ドライブ/Kuroda lab/Research/Metabolome/result/Property/20220307/comp10?/pvals.xlsx',header=0,index_col=0)\n",
    "    #ICAClss.AnalKEGG(save_dir)\n",
    "    #ICAClss.AnalnanScoreCorr(ClusterMeanMetasamples,ClusterMeanMetagenes,OptionDict,save_dir)\n",
    "    #ICAClss.AnalNanEnrich(metagenes,list(metagenes.index),OptionDict,save_dir)\n",
    "    ICAClss.mkTablegenePathway(pvals,save_dir)\n",
    "    \n",
    "    ICAClss.Analeachcomponents(metasamples,metasamples,save_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    del(AnalHel)\n",
    "    import AnalHelper as AnalHel \n",
    "\n",
    "    AnalClss = AnalHel.Anal_class()\n",
    "    import sys\n",
    "    import pprint\n",
    "    \n",
    "    pprint.pprint(sys.path)\n",
    "    importlib.reload(AnalHel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
